{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_문장의 표현_Sentence Representation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "52uiZhBWaR4M"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fininsight/text-mining-tutorial/blob/master/2_%EB%AC%B8%EC%9E%A5%EC%9D%98_%ED%91%9C%ED%98%84_Sentence_Representation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zEFesPBvXe2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 문장의 표현 (Sentence Representation)"
      ]
    },
    {
      "metadata": {
        "id": "52uiZhBWaR4M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1 BoW (Bag of Words)"
      ]
    },
    {
      "metadata": {
        "id": "xuz1lvCi_e-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://image.slidesharecdn.com/vector-space-models-170118145044/95/cs571-vector-space-models-3-638.jpg?cb=1485433004\" />\n",
        "\n",
        "https://en.wikipedia.org/wiki/Bag-of-words_model\n",
        "https://www.slideshare.net/jchoi7s/cs571-vector-space-models"
      ]
    },
    {
      "metadata": {
        "id": "jUABPDuYAO7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 동물원 예제"
      ]
    },
    {
      "metadata": {
        "id": "dPZCmyM7aR4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_ls = [\n",
        " '오늘 동물원에서 코끼리를 봤어',\n",
        " '오늘 동물원에서 원숭이에게 사과를 줬어'   \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zuMcIp6_aR4R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) 띄어쓰기 단위로 토큰화"
      ]
    },
    {
      "metadata": {
        "id": "HK8UIQfKaR4S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_ls = [sentence.split() for sentence in sentence_ls]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-E2fakIGaR4U",
        "colab_type": "code",
        "outputId": "0fc42440-ed4a-4c19-a5e2-124c40668048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sentence_ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['오늘', '동물원에서', '코끼리를', '봤어'], ['오늘', '동물원에서', '원숭이에게', '사과를', '줬어']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "vxOK8R52aR4X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) 각 고유 토큰에 인덱스(Index)를 지정"
      ]
    },
    {
      "metadata": {
        "id": "HjQvx_d1aR4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "token_dict = defaultdict(lambda : len(token_dict))\n",
        "\n",
        "for sentence in sentence_ls:\n",
        "    for token in sentence:\n",
        "        token_dict[token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qHzASAoCaR4a",
        "colab_type": "code",
        "outputId": "e5215068-81b3-41a7-a6c6-9459064c6da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "token_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {'동물원에서': 1,\n",
              "             '봤어': 3,\n",
              "             '사과를': 5,\n",
              "             '오늘': 0,\n",
              "             '원숭이에게': 4,\n",
              "             '줬어': 6,\n",
              "             '코끼리를': 2})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "BBi-jFhVaR4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3) 토큰 인덱스 정렬"
      ]
    },
    {
      "metadata": {
        "id": "Qn3hkjJuaR4d",
        "colab_type": "code",
        "outputId": "8b622e68-6add-46d4-a262-e25e2e156bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "index_token_ls = sorted((value, key) for key, value in token_dict.items())\n",
        "index_token_ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '오늘'),\n",
              " (1, '동물원에서'),\n",
              " (2, '코끼리를'),\n",
              " (3, '봤어'),\n",
              " (4, '원숭이에게'),\n",
              " (5, '사과를'),\n",
              " (6, '줬어')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "qAg_or1naR4f",
        "colab_type": "code",
        "outputId": "d3938aae-4719-494f-fd2c-ea33bc6559d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "token_in_order = [tup[1] for tup in index_token_ls]\n",
        "token_in_order"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['오늘', '동물원에서', '코끼리를', '봤어', '원숭이에게', '사과를', '줬어']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "3ELkZo_BaR4h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4) 빈(empty) BOW 생성"
      ]
    },
    {
      "metadata": {
        "id": "ct2qziLJaR4i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "n_words = len(token_dict) # 전체 고유 토큰의 수\n",
        "n_sentence = len(sentence_ls) # 전체 문장의 수\n",
        "\n",
        "BOW = pd.DataFrame(\n",
        "    np.zeros((n_sentence, n_words)),\n",
        "    columns = token_in_order,\n",
        "    index = ['문장_1', '문장_2'],\n",
        "    dtype = int,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8-PznHAaR4k",
        "colab_type": "code",
        "outputId": "0200aaee-ba6b-4e4e-84e9-b77b30c9565c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "BOW"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>오늘</th>\n",
              "      <th>동물원에서</th>\n",
              "      <th>코끼리를</th>\n",
              "      <th>봤어</th>\n",
              "      <th>원숭이에게</th>\n",
              "      <th>사과를</th>\n",
              "      <th>줬어</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문장_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문장_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      오늘  동물원에서  코끼리를  봤어  원숭이에게  사과를  줬어\n",
              "문장_1   0      0     0   0      0    0   0\n",
              "문장_2   0      0     0   0      0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "G7cZKHjeaR4n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5) 각 토큰을 BOW에 하나씩 담는다."
      ]
    },
    {
      "metadata": {
        "id": "Jd4Gyeh4aR4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentence_ls):\n",
        "    for token in sentence:\n",
        "        \n",
        "        token_location = token_dict[token] # 해당 토큰의 위치(column)\n",
        "        BOW.iloc[i, token_location] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSJ2jydTaR4p",
        "colab_type": "code",
        "outputId": "7227ed3e-4c1b-4884-9619-a759bf701069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "BOW"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>오늘</th>\n",
              "      <th>동물원에서</th>\n",
              "      <th>코끼리를</th>\n",
              "      <th>봤어</th>\n",
              "      <th>원숭이에게</th>\n",
              "      <th>사과를</th>\n",
              "      <th>줬어</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문장_1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문장_2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      오늘  동물원에서  코끼리를  봤어  원숭이에게  사과를  줬어\n",
              "문장_1   1      1     1   1      0    0   0\n",
              "문장_2   1      1     0   0      1    1   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "hx3EGCegbh8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CHnBJ8wuaR4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 양념치킨과 후라이드치킨 예제"
      ]
    },
    {
      "metadata": {
        "id": "4UZDtYS7aR4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_ls = ['나는 양념 치킨을 좋아해 하지만 후라이드 치킨을 싫어해',\n",
        "               '나는 후라이드 치킨을 좋아해 하지만 양념 치킨을 싫어해']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmXVteHEaR4x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1) 띄어쓰기 단위로 토큰화"
      ]
    },
    {
      "metadata": {
        "id": "TO8Vnn2SaR4y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_ls = [sentence.split() for sentence in sentence_ls]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTMWP5GjaR40",
        "colab_type": "code",
        "outputId": "8ac0f629-84af-407d-e864-25945a458855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "sentence_ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['나는', '양념', '치킨을', '좋아해', '하지만', '후라이드', '치킨을', '싫어해'],\n",
              " ['나는', '후라이드', '치킨을', '좋아해', '하지만', '양념', '치킨을', '싫어해']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "edQ76L6EaR44",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2) 각 고유 토큰에 인덱스(Index)를 지정"
      ]
    },
    {
      "metadata": {
        "id": "6GZSTsvSaR44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "token_dict = defaultdict(lambda : len(token_dict))\n",
        "\n",
        "for sentence in sentence_ls:\n",
        "    for token in sentence:\n",
        "        token_dict[token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLXtAuLEaR46",
        "colab_type": "code",
        "outputId": "2bdac26b-1268-4cbc-a26a-48ba64a0886a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "token_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {'나는': 0,\n",
              "             '싫어해': 6,\n",
              "             '양념': 1,\n",
              "             '좋아해': 3,\n",
              "             '치킨을': 2,\n",
              "             '하지만': 4,\n",
              "             '후라이드': 5})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "BNKgIOkdaR4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3) 토큰 인덱스 정렬"
      ]
    },
    {
      "metadata": {
        "id": "H3Sk7-lJaR4-",
        "colab_type": "code",
        "outputId": "28007099-efcc-420a-c733-b4f387d705ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "index_token_ls = sorted((value, key) for key, value in token_dict.items())\n",
        "index_token_ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '나는'),\n",
              " (1, '양념'),\n",
              " (2, '치킨을'),\n",
              " (3, '좋아해'),\n",
              " (4, '하지만'),\n",
              " (5, '후라이드'),\n",
              " (6, '싫어해')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "BEBwPXl7aR5A",
        "colab_type": "code",
        "outputId": "526890fa-be4e-47aa-df65-b17f88922c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "token_in_order = [tup[1] for tup in index_token_ls]\n",
        "token_in_order"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나는', '양념', '치킨을', '좋아해', '하지만', '후라이드', '싫어해']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "QmgGxyL7aR5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4) 빈(empty) BOW 생성"
      ]
    },
    {
      "metadata": {
        "id": "_pmg9xo2aR5F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "n_words = len(token_dict) # 전체 고유 토큰의 수\n",
        "n_sentence = len(sentence_ls) # 전체 문장의 수\n",
        "\n",
        "BOW = pd.DataFrame(\n",
        "    np.zeros((n_sentence, n_words)),\n",
        "    columns = token_in_order,\n",
        "    index = ['문장_1', '문장_2'],\n",
        "    dtype = int,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNj8f-lvaR5H",
        "colab_type": "code",
        "outputId": "f46dce9f-30a0-4f3f-ccc5-1f9afe8e5ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "BOW"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>나는</th>\n",
              "      <th>양념</th>\n",
              "      <th>치킨을</th>\n",
              "      <th>좋아해</th>\n",
              "      <th>하지만</th>\n",
              "      <th>후라이드</th>\n",
              "      <th>싫어해</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문장_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문장_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      나는  양념  치킨을  좋아해  하지만  후라이드  싫어해\n",
              "문장_1   0   0    0    0    0     0    0\n",
              "문장_2   0   0    0    0    0     0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "HiQkXwbkaR5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5) 각 토큰을 BOW에 하나씩 담는다."
      ]
    },
    {
      "metadata": {
        "id": "hIICxX7DaR5K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentence_ls):\n",
        "    for token in sentence:\n",
        "        \n",
        "        token_location = token_dict[token] # 해당 토큰의 위치(column)\n",
        "        BOW.iloc[i, token_location] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zL3v6nnjaR5M",
        "colab_type": "code",
        "outputId": "c24806e3-24a3-4a33-bfc1-dabdc5b945bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "BOW"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>나는</th>\n",
              "      <th>양념</th>\n",
              "      <th>치킨을</th>\n",
              "      <th>좋아해</th>\n",
              "      <th>하지만</th>\n",
              "      <th>후라이드</th>\n",
              "      <th>싫어해</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문장_1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문장_2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      나는  양념  치킨을  좋아해  하지만  후라이드  싫어해\n",
              "문장_1   1   1    2    1    1     1    1\n",
              "문장_2   1   1    2    1    1     1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "491wb8Avb4ij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Hlu7kB_fDyer",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://en.wikipedia.org/wiki/Document-term_matrix"
      ]
    },
    {
      "metadata": {
        "id": "lYoJ_zN4BqtH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2 TDM(Term-Document Matrix)"
      ]
    },
    {
      "metadata": {
        "id": "MM4_XrUuDB6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d1 = '오늘 동물원에서 원숭이를 봤어'\n",
        "d2 = '오늘 동물원에서 코끼리를 봤어'\n",
        "d3 = '동물원에서 원숭이에게 바나나를 줬어'\n",
        "\n",
        "document_ls = [d1, d2, d3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wOrXXr7rDaF8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) 띄어쓰기 단위 토큰화"
      ]
    },
    {
      "metadata": {
        "id": "LmbeAkHUDg7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d8f31b57-8440-427a-88aa-ad807ab9b008"
      },
      "cell_type": "code",
      "source": [
        "document_ls = [document.split() for document in document_ls]\n",
        "document_ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['오늘', '동물원에서', '원숭이를', '봤어'],\n",
              " ['오늘', '동물원에서', '코끼리를', '봤어'],\n",
              " ['동물원에서', '원숭이에게', '바나나를', '줬어']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "vTaZTIRQDxX1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) 각 고유 토큰에 인덱스(Index) 지정"
      ]
    },
    {
      "metadata": {
        "id": "xYovrqPZEM8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "token_dict = defaultdict(lambda : len(token_dict))\n",
        "\n",
        "for document in document_ls:\n",
        "    for token in document:\n",
        "        token_dict[token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wMReALjERqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "66c7f060-3c95-4c42-e70a-4421b498ad11"
      },
      "cell_type": "code",
      "source": [
        "token_dict"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {'동물원에서': 1,\n",
              "             '바나나를': 6,\n",
              "             '봤어': 3,\n",
              "             '오늘': 0,\n",
              "             '원숭이를': 2,\n",
              "             '원숭이에게': 5,\n",
              "             '줬어': 7,\n",
              "             '코끼리를': 4})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "HzPojRQGD4JK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3) 토큰 인덱스 정렬"
      ]
    },
    {
      "metadata": {
        "id": "ECUzO8llEWu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "0851c036-7504-43e0-f12f-104091c5fdb0"
      },
      "cell_type": "code",
      "source": [
        "index_token_ls = sorted((value, key) for key, value in token_dict.items())\n",
        "index_token_ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '오늘'),\n",
              " (1, '동물원에서'),\n",
              " (2, '원숭이를'),\n",
              " (3, '봤어'),\n",
              " (4, '코끼리를'),\n",
              " (5, '원숭이에게'),\n",
              " (6, '바나나를'),\n",
              " (7, '줬어')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "dnQ5W2ZgEnbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77b9e023-9cef-4b7e-f3bf-273b03a356d5"
      },
      "cell_type": "code",
      "source": [
        "token_in_order = [tup[1] for tup in index_token_ls]\n",
        "token_in_order"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['오늘', '동물원에서', '원숭이를', '봤어', '코끼리를', '원숭이에게', '바나나를', '줬어']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "XNTLjC_7D6vv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4) 빈(empty) TDM 생성"
      ]
    },
    {
      "metadata": {
        "id": "k6X4h6SNEa7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "n_words = len(token_dict) # 전체 고유 토큰의 수\n",
        "n_document = len(document_ls) # 전체 문서의 수\n",
        "\n",
        "TDM = pd.DataFrame(\n",
        "    np.zeros((n_document, n_words)),\n",
        "    columns = token_in_order,\n",
        "    index = ['문서_1', '문서_2', '문서_3'],\n",
        "    dtype = int,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCZGq2fhEx75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "d3fade46-fce9-490a-ffca-9fc838bbea04"
      },
      "cell_type": "code",
      "source": [
        "TDM"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>오늘</th>\n",
              "      <th>동물원에서</th>\n",
              "      <th>원숭이를</th>\n",
              "      <th>봤어</th>\n",
              "      <th>코끼리를</th>\n",
              "      <th>원숭이에게</th>\n",
              "      <th>바나나를</th>\n",
              "      <th>줬어</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문서_1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문서_2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문서_3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      오늘  동물원에서  원숭이를  봤어  코끼리를  원숭이에게  바나나를  줬어\n",
              "문서_1   0      0     0   0     0      0     0   0\n",
              "문서_2   0      0     0   0     0      0     0   0\n",
              "문서_3   0      0     0   0     0      0     0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Ja1HqdptD_a_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5) 각 토큰을 TDM에 담는다"
      ]
    },
    {
      "metadata": {
        "id": "X6USVYHcE1of",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, document in enumerate(document_ls):\n",
        "    for token in document:\n",
        "        \n",
        "        token_location = token_dict[token] # 해당 토큰의 위치(column)\n",
        "        TDM.iloc[i, token_location] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBQyD7NvE8vT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "414e3029-a292-4311-aed7-f367a3afd392"
      },
      "cell_type": "code",
      "source": [
        "TDM"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>오늘</th>\n",
              "      <th>동물원에서</th>\n",
              "      <th>원숭이를</th>\n",
              "      <th>봤어</th>\n",
              "      <th>코끼리를</th>\n",
              "      <th>원숭이에게</th>\n",
              "      <th>바나나를</th>\n",
              "      <th>줬어</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문서_1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문서_2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문서_3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      오늘  동물원에서  원숭이를  봤어  코끼리를  원숭이에게  바나나를  줬어\n",
              "문서_1   1      1     1   1     0      0     0   0\n",
              "문서_2   1      1     0   1     1      0     0   0\n",
              "문서_3   0      1     0   0     0      1     1   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "TmnWDmSpBwBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3 TF-IDF (Term Frequency-Inverse Document Frequency)"
      ]
    },
    {
      "metadata": {
        "id": "NjKCX0atD4rM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/10109d0e60cc9d50a1ea2f189bac0ac29a030a00\" />\n",
        "\n",
        "\n",
        "\n",
        "*  TF(단어 빈도, Term Frequency) : 단어가 문서 내에 등장하는 빈도\n",
        "*  IDF(역문서 빈도, Inverse Document Frequency) : 단어가 여러 문서에 공통적으로 등장하는 빈도\n",
        "*  한 문서 내에 자주 등장하고 다른 문서에 자주 등장하지 않는 단어를 주요 단어로 판별할 수 있음\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Logarithm_plots.png/300px-Logarithm_plots.png\" />\n",
        "\n",
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
      ]
    },
    {
      "metadata": {
        "id": "WNKTLfkAHdJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d1 = \"The cat sat on my face\"\n",
        "d2 = \"The dog sat on my bed\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQLa8GJWKYqU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1 직접계산하기 1"
      ]
    },
    {
      "metadata": {
        "id": "KEiBvluT9vIJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "weighting schema|weight\n",
        "--|--\n",
        "tf (term frequency)|<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/91699003abf4fe8bdf861bbce08e73e71acf5fd4\" />\n",
        "idf(inverse document frequency) |<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/864fcfdc0c16344c11509f724f1aa7081cf9f657\" />"
      ]
    },
    {
      "metadata": {
        "id": "1bptdTrtIOIe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) 띄어쓰기 단위 토큰화"
      ]
    },
    {
      "metadata": {
        "id": "iZ4GIQWVHdJ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bowA = d1.split()\n",
        "bowB = d2.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2ZAERDwHdJ4",
        "colab_type": "code",
        "outputId": "7e9a0eef-ddc3-4601-8281-8f642edd0fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "bowB"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'dog', 'sat', 'on', 'my', 'bed']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "QECQCCBvKENE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) TDM 생성"
      ]
    },
    {
      "metadata": {
        "id": "UsBl-oP6HdJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wordSet = set(bowA).union(set(bowB))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6OUO08sHdKA",
        "colab_type": "code",
        "outputId": "84433926-4bbf-4eec-96c7-a31423a0eddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "wordSet"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The', 'bed', 'cat', 'dog', 'face', 'my', 'on', 'sat'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "_IcpIlc5HdKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wordDictA = dict.fromkeys(wordSet, 0) \n",
        "wordDictB = dict.fromkeys(wordSet, 0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XhBzZzriHdKH",
        "colab_type": "code",
        "outputId": "182a69ac-1299-4625-8d1c-d48d025750f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "wordDictA"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0, 'bed': 0, 'cat': 0, 'dog': 0, 'face': 0, 'my': 0, 'on': 0, 'sat': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "BauIgbePHdKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for word in bowA:\n",
        "    wordDictA[word]+=1\n",
        "    \n",
        "for word in bowB:\n",
        "    wordDictB[word]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iEBYiLMyHdKN",
        "colab_type": "code",
        "outputId": "cdea7fe6-e84a-42e0-b504-6da38d3b549d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "wordDictA"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 1, 'bed': 0, 'cat': 1, 'dog': 0, 'face': 1, 'my': 1, 'on': 1, 'sat': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "qv0LtT2bHdKQ",
        "colab_type": "code",
        "outputId": "990bc783-f90c-4bd5-c38a-fb37ea621022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame([wordDictA, wordDictB])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>bed</th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>face</th>\n",
              "      <th>my</th>\n",
              "      <th>on</th>\n",
              "      <th>sat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   The  bed  cat  dog  face  my  on  sat\n",
              "0    1    0    1    0     1   1   1    1\n",
              "1    1    1    0    1     0   1   1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "1CwtCbPpKInm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3) TF 계산"
      ]
    },
    {
      "metadata": {
        "id": "IoIAj3Tl88da",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/91699003abf4fe8bdf861bbce08e73e71acf5fd4\" />"
      ]
    },
    {
      "metadata": {
        "id": "aXLKyRuLHdKe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def computeTF(wordDict, bow):\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-o2zYkK3HdKp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfBowA = computeTF(wordDictA, bowA)\n",
        "tfBowB = computeTF(wordDictB, bowB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fd3wWC8lHdKr",
        "colab_type": "code",
        "outputId": "0686b5e6-94a6-47d8-a435-ec73f8df56f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "tfBowA"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0.16666666666666666,\n",
              " 'bed': 0.0,\n",
              " 'cat': 0.16666666666666666,\n",
              " 'dog': 0.0,\n",
              " 'face': 0.16666666666666666,\n",
              " 'my': 0.16666666666666666,\n",
              " 'on': 0.16666666666666666,\n",
              " 'sat': 0.16666666666666666}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZx4IAUFHdKu",
        "colab_type": "code",
        "outputId": "4153f336-a0d4-4f7b-932b-546204413041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "tfBowB"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0.16666666666666666,\n",
              " 'bed': 0.16666666666666666,\n",
              " 'cat': 0.0,\n",
              " 'dog': 0.16666666666666666,\n",
              " 'face': 0.0,\n",
              " 'my': 0.16666666666666666,\n",
              " 'on': 0.16666666666666666,\n",
              " 'sat': 0.16666666666666666}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "cWtq-XvuKO5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4) IDF  계산"
      ]
    },
    {
      "metadata": {
        "id": "Ve7FkpIi9UVf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/864fcfdc0c16344c11509f724f1aa7081cf9f657\" />"
      ]
    },
    {
      "metadata": {
        "id": "-4SS2ol1HdKz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def computeIDF(docList):\n",
        "    import math\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / float(val))\n",
        "        \n",
        "    return idfDict    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8IItDkbrHdK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idfs = computeIDF([wordDictA, wordDictB])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBvQxDBcKS60",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5) TF-IDF 계산"
      ]
    },
    {
      "metadata": {
        "id": "cL4oRjrrHdLG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return tfidf\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xumPZQmNHdLI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidfBowA = computeTFIDF(tfBowA, idfs)\n",
        "tfidfBowB = computeTFIDF(tfBowB, idfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Ncmyd8hHdLJ",
        "colab_type": "code",
        "outputId": "90ab2150-fc03-4500-dc84-ed3ba155ec07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame([tfidfBowA, tfidfBowB])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>bed</th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>face</th>\n",
              "      <th>my</th>\n",
              "      <th>on</th>\n",
              "      <th>sat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   The       bed       cat       dog      face   my   on  sat\n",
              "0  0.0  0.000000  0.050172  0.000000  0.050172  0.0  0.0  0.0\n",
              "1  0.0  0.050172  0.000000  0.050172  0.000000  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "-cwnRnyH5Ox6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2 직접계산하기2"
      ]
    },
    {
      "metadata": {
        "id": "Y8lmTqCA9ZBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "weighting schema|weight\n",
        "--|--\n",
        "tf(double normalization 0.5)|<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/45badc1c70ec2caa00ed8c21ed75bd9f8d3e650c\" />\n",
        "idf(inverse document frequency smooth)|<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/23e5ae785c1ddc6bd95d404ea3fac2477fff5eff\" />"
      ]
    },
    {
      "metadata": {
        "id": "eO1kEEmceE1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "421988a1-f70b-4ac8-d73b-ad5fcf2d5408"
      },
      "cell_type": "code",
      "source": [
        "from math import log10\n",
        "\n",
        "# document 내 토큰이 등장한 빈도수 계산\n",
        "def f(t, d):\n",
        "    return d.count(t)\n",
        "\n",
        "# tf 계산\n",
        "def tf(t, d):\n",
        "    return 0.5 + 0.5*f(t,d)/max([f(w,d) for w in d])\n",
        "\n",
        "# idf 계산\n",
        "def idf(t, D):\n",
        "    numerator = len(D)\n",
        "    denominator = 1 + len([ True for d in D if t in d])\n",
        "    return log10(numerator/denominator)\n",
        "\n",
        "# tf-idf 계산\n",
        "def tfidf(t, d, D):\n",
        "    return tf(t,d)*idf(t, D)\n",
        "\n",
        "# 공백을 기준으로 토큰과\n",
        "def tokenizer(d):\n",
        "    return d.split()\n",
        "\n",
        "# tfidf 계산  \n",
        "def tfidfScorer(D):\n",
        "    tokenized_D = [tokenizer(d) for d in D]\n",
        "    result = []\n",
        "    for d in tokenized_D:\n",
        "        result.append([(t, tfidf(t, d, tokenized_D)) for t in d])\n",
        "    return result\n",
        "\n",
        "corpus = [d1, d2]\n",
        "\n",
        "for i, doc in enumerate(tfidfScorer(corpus)):\n",
        "    print('====== document[%d] ======' % i)\n",
        "    print(doc)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== document[0] ======\n",
            "[('The', -0.17609125905568127), ('cat', 0.0), ('sat', -0.17609125905568127), ('on', -0.17609125905568127), ('my', -0.17609125905568127), ('face', 0.0)]\n",
            "====== document[1] ======\n",
            "[('The', -0.17609125905568127), ('dog', 0.0), ('sat', -0.17609125905568127), ('on', -0.17609125905568127), ('my', -0.17609125905568127), ('bed', 0.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "huJ0-b2bKb_8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2 sklearn 사용하여 계산하기"
      ]
    },
    {
      "metadata": {
        "id": "clXas7E3d8v0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "2405428d-d1cf-4a71-b9eb-7b5739beb519"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "\n",
        "corpus = [d1, d2]\n",
        "\n",
        "# ============================================\n",
        "# -- Get TFIDF\n",
        "# ============================================\n",
        "vectorizer = TfidfVectorizer()\n",
        "sp_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "word2id = defaultdict(lambda : 0)\n",
        "for idx, feature in enumerate(vectorizer.get_feature_names()):\n",
        "    word2id[feature] = idx\n",
        "\n",
        "for i, sent in enumerate(corpus):\n",
        "    print('====== document[%d] ======' % i)\n",
        "    print( [ (token, sp_matrix[i, word2id[token]]) for token in sent.split() ] )"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== document[0] ======\n",
            "[('The', 0.0), ('cat', 0.49844627974580596), ('sat', 0.35464863330313684), ('on', 0.35464863330313684), ('my', 0.35464863330313684), ('face', 0.49844627974580596)]\n",
            "====== document[1] ======\n",
            "[('The', 0.49844627974580596), ('dog', 0.49844627974580596), ('sat', 0.35464863330313684), ('on', 0.35464863330313684), ('my', 0.35464863330313684), ('bed', 0.49844627974580596)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uucW3BFQMUAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "C1bFCpsIaSCU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4 CBoW (Continious Bag of Words)"
      ]
    },
    {
      "metadata": {
        "id": "SUmInaheaSCV",
        "colab_type": "code",
        "outputId": "bd6bac4f-cc4d-4817-d4bb-dd5ee5208afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9ab32c83b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "vnX1M86_aSCX",
        "colab_type": "code",
        "outputId": "fa5ff4b8-88af-4524-f9e0-33444a279d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
        "\n",
        "\n",
        "vocab = list(set(sentence))\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "o-Q8PT-zaSCa",
        "colab_type": "code",
        "outputId": "2ee26b71-0ca2-419b-c829-64aab87f33fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "data = \\\n",
        "[([sentence[idx-2],sentence[idx-1],sentence[idx+1],sentence[idx+2]],sentence[idx])\\\n",
        " for idx in range(2,len(sentence)-2)]\n",
        "print(data[:3],end='\\n\\n\\n')\n",
        "\n",
        "word_to_ix = {val : idx for idx,val in enumerate(vocab)}\n",
        "print(word_to_ix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['When', 'forty', 'shall', 'besiege'], 'winters'), (['forty', 'winters', 'besiege', 'thy'], 'shall'), (['winters', 'shall', 'thy', 'brow,'], 'besiege')]\n",
            "\n",
            "\n",
            "{'How': 0, 'lies,': 1, 'livery': 2, 'treasure': 3, 'small': 4, 'gazed': 5, 'warm': 6, 'all': 7, 'shame,': 8, 'use,': 9, 'by': 10, 'fair': 11, 'blood': 12, 'were': 13, 'dig': 14, 'thriftless': 15, 'worth': 16, 'new': 17, \"beauty's\": 18, 'Were': 19, 'being': 20, 'the': 21, 'sunken': 22, 'his': 23, 'thy': 24, \"totter'd\": 25, 'deep': 26, \"feel'st\": 27, 'And': 28, 'when': 29, \"deserv'd\": 30, 'child': 31, 'forty': 32, 'besiege': 33, 'see': 34, 'When': 35, 'beauty': 36, 'To': 37, 'weed': 38, 'eyes,': 39, \"excuse,'\": 40, 'brow,': 41, 'now,': 42, 'shall': 43, \"youth's\": 44, 'on': 45, 'old,': 46, 'lusty': 47, 'praise': 48, 'couldst': 49, 'Thy': 50, 'art': 51, 'This': 52, 'all-eating': 53, 'and': 54, 'made': 55, 'make': 56, 'in': 57, 'Will': 58, 'an': 59, 'where': 60, 'it': 61, 'sum': 62, 'thou': 63, 'proud': 64, 'held:': 65, \"'This\": 66, 'thine!': 67, 'succession': 68, 'If': 69, 'Where': 70, 'field,': 71, 'within': 72, 'of': 73, 'Proving': 74, 'praise.': 75, 'my': 76, 'much': 77, 'trenches': 78, 'mine': 79, 'Then': 80, 'own': 81, 'thine': 82, 'days;': 83, 'so': 84, 'old': 85, 'say,': 86, 'Shall': 87, 'winters': 88, 'answer': 89, 'more': 90, 'count,': 91, 'be': 92, 'asked,': 93, 'to': 94, 'cold.': 95, 'a': 96}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bi79GEB9aSCc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module) : \n",
        "    \n",
        "    def __init__(self,vocab_size, embedding_dim):  \n",
        "        \n",
        "        super(CBOW,self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = 10#embedding_size\n",
        "        self.embeddings = nn.Embedding(self.vocab_size,self.embedding_dim)\n",
        "        self.linear1 = nn.Linear(self.embedding_dim,128)\n",
        "        self.linear2 = nn.Linear(128,self.vocab_size)\n",
        "    \n",
        "    def forward(self,inputs) : \n",
        "        self.embeds = self.embeddings(inputs).sum(dim=0).unsqueeze(0)\n",
        "        out = F.relu(self.linear1(self.embeds))\n",
        "        out = self.linear2(out)\n",
        "            \n",
        "        log_probs = F.log_softmax(out,dim=1)\n",
        "        return log_probs\n",
        "    \n",
        "    def get_word_vector(self,target,word_to_ix) : \n",
        "        word2id = torch.LongTensor([word_to_ix[target]])\n",
        "        return self.embeddings(word2id).view(1, -1)\n",
        "        \n",
        "    \n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    word2id = torch.tensor(idxs, dtype=torch.long)\n",
        "    return word2id\n",
        "\n",
        "def make_target_vector(target, word_to_ix):\n",
        "    idxs = [word_to_ix[target]]\n",
        "    return torch.LongTensor(idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3lfwLI8WaSCf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 10\n",
        "EPOCH = 20\n",
        "VERVOSE = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6s_6R-kaSCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_cbow(vocab_size , word_to_ix) :\n",
        "    loss_function = nn.NLLLoss()\n",
        "    model = CBOW(vocab_size, EMBEDDING_DIM)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        total_loss = 0\n",
        "        for context, target in data:\n",
        "\n",
        "            # 아래의 프로세스는 word : ID 로 converting 시켜주는 process 이다.\n",
        "            context_idxs = make_context_vector(context,word_to_ix)\n",
        "            target_idxs = torch.LongTensor([word_to_ix[target]])\n",
        "\n",
        "            # pytorch는 gradient 를 누진적으로 계산하기 때문에, 0으로 만들어주어야한다.\n",
        "            model.zero_grad()\n",
        "\n",
        "            # input 값을 넣으면 log_probs 라는 output 값이 나온다.\n",
        "            log_probs = model(context_idxs)\n",
        "\n",
        "            # 이 값을 위에서 정의한 손실 함수를 기반으로 loss 를 계산한다.\n",
        "            loss = loss_function(log_probs, target_idxs)\n",
        "\n",
        "            # 위에서 나온 loss를 기반으로 back propagation 을 돌린다.\n",
        "            # 또한, optimizer 를 update 하면서 parameter 또한 update 한다.\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss\n",
        "\n",
        "            if epoch % VERVOSE == 0 : \n",
        "                loss_avg = float(total_loss / len(data))\n",
        "                print(\"{}/{} loss {:.2f}\".format(epoch, EPOCH, loss_avg))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRUoUQRYaSCj",
        "colab_type": "code",
        "outputId": "f35073aa-928d-4b02-967d-50ce81515c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8099
        }
      },
      "cell_type": "code",
      "source": [
        "run_cbow(vocab_size , word_to_ix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/20 loss 0.04\n",
            "0/20 loss 0.09\n",
            "0/20 loss 0.13\n",
            "0/20 loss 0.17\n",
            "0/20 loss 0.21\n",
            "0/20 loss 0.25\n",
            "0/20 loss 0.30\n",
            "0/20 loss 0.34\n",
            "0/20 loss 0.38\n",
            "0/20 loss 0.41\n",
            "0/20 loss 0.45\n",
            "0/20 loss 0.50\n",
            "0/20 loss 0.54\n",
            "0/20 loss 0.59\n",
            "0/20 loss 0.64\n",
            "0/20 loss 0.68\n",
            "0/20 loss 0.71\n",
            "0/20 loss 0.76\n",
            "0/20 loss 0.81\n",
            "0/20 loss 0.85\n",
            "0/20 loss 0.89\n",
            "0/20 loss 0.92\n",
            "0/20 loss 0.95\n",
            "0/20 loss 1.00\n",
            "0/20 loss 1.04\n",
            "0/20 loss 1.08\n",
            "0/20 loss 1.12\n",
            "0/20 loss 1.17\n",
            "0/20 loss 1.23\n",
            "0/20 loss 1.27\n",
            "0/20 loss 1.31\n",
            "0/20 loss 1.35\n",
            "0/20 loss 1.39\n",
            "0/20 loss 1.43\n",
            "0/20 loss 1.48\n",
            "0/20 loss 1.52\n",
            "0/20 loss 1.55\n",
            "0/20 loss 1.60\n",
            "0/20 loss 1.65\n",
            "0/20 loss 1.69\n",
            "0/20 loss 1.73\n",
            "0/20 loss 1.77\n",
            "0/20 loss 1.81\n",
            "0/20 loss 1.85\n",
            "0/20 loss 1.90\n",
            "0/20 loss 1.94\n",
            "0/20 loss 1.98\n",
            "0/20 loss 2.03\n",
            "0/20 loss 2.07\n",
            "0/20 loss 2.10\n",
            "0/20 loss 2.15\n",
            "0/20 loss 2.19\n",
            "0/20 loss 2.23\n",
            "0/20 loss 2.27\n",
            "0/20 loss 2.31\n",
            "0/20 loss 2.36\n",
            "0/20 loss 2.40\n",
            "0/20 loss 2.44\n",
            "0/20 loss 2.49\n",
            "0/20 loss 2.54\n",
            "0/20 loss 2.59\n",
            "0/20 loss 2.63\n",
            "0/20 loss 2.68\n",
            "0/20 loss 2.72\n",
            "0/20 loss 2.76\n",
            "0/20 loss 2.81\n",
            "0/20 loss 2.85\n",
            "0/20 loss 2.89\n",
            "0/20 loss 2.93\n",
            "0/20 loss 2.97\n",
            "0/20 loss 3.02\n",
            "0/20 loss 3.06\n",
            "0/20 loss 3.10\n",
            "0/20 loss 3.15\n",
            "0/20 loss 3.20\n",
            "0/20 loss 3.24\n",
            "0/20 loss 3.28\n",
            "0/20 loss 3.31\n",
            "0/20 loss 3.35\n",
            "0/20 loss 3.40\n",
            "0/20 loss 3.44\n",
            "0/20 loss 3.48\n",
            "0/20 loss 3.52\n",
            "0/20 loss 3.56\n",
            "0/20 loss 3.61\n",
            "0/20 loss 3.65\n",
            "0/20 loss 3.69\n",
            "0/20 loss 3.73\n",
            "0/20 loss 3.76\n",
            "0/20 loss 3.79\n",
            "0/20 loss 3.84\n",
            "0/20 loss 3.88\n",
            "0/20 loss 3.93\n",
            "0/20 loss 3.97\n",
            "0/20 loss 4.01\n",
            "0/20 loss 4.06\n",
            "0/20 loss 4.11\n",
            "0/20 loss 4.15\n",
            "0/20 loss 4.19\n",
            "0/20 loss 4.23\n",
            "0/20 loss 4.27\n",
            "0/20 loss 4.31\n",
            "0/20 loss 4.35\n",
            "0/20 loss 4.39\n",
            "0/20 loss 4.44\n",
            "0/20 loss 4.48\n",
            "0/20 loss 4.52\n",
            "0/20 loss 4.56\n",
            "0/20 loss 4.61\n",
            "0/20 loss 4.66\n",
            "0/20 loss 4.70\n",
            "5/20 loss 0.04\n",
            "5/20 loss 0.08\n",
            "5/20 loss 0.12\n",
            "5/20 loss 0.16\n",
            "5/20 loss 0.20\n",
            "5/20 loss 0.23\n",
            "5/20 loss 0.27\n",
            "5/20 loss 0.31\n",
            "5/20 loss 0.34\n",
            "5/20 loss 0.37\n",
            "5/20 loss 0.41\n",
            "5/20 loss 0.45\n",
            "5/20 loss 0.49\n",
            "5/20 loss 0.54\n",
            "5/20 loss 0.58\n",
            "5/20 loss 0.62\n",
            "5/20 loss 0.66\n",
            "5/20 loss 0.70\n",
            "5/20 loss 0.75\n",
            "5/20 loss 0.79\n",
            "5/20 loss 0.83\n",
            "5/20 loss 0.85\n",
            "5/20 loss 0.89\n",
            "5/20 loss 0.93\n",
            "5/20 loss 0.97\n",
            "5/20 loss 1.01\n",
            "5/20 loss 1.05\n",
            "5/20 loss 1.09\n",
            "5/20 loss 1.14\n",
            "5/20 loss 1.19\n",
            "5/20 loss 1.22\n",
            "5/20 loss 1.26\n",
            "5/20 loss 1.30\n",
            "5/20 loss 1.34\n",
            "5/20 loss 1.39\n",
            "5/20 loss 1.42\n",
            "5/20 loss 1.45\n",
            "5/20 loss 1.50\n",
            "5/20 loss 1.54\n",
            "5/20 loss 1.58\n",
            "5/20 loss 1.62\n",
            "5/20 loss 1.66\n",
            "5/20 loss 1.69\n",
            "5/20 loss 1.73\n",
            "5/20 loss 1.78\n",
            "5/20 loss 1.82\n",
            "5/20 loss 1.86\n",
            "5/20 loss 1.90\n",
            "5/20 loss 1.94\n",
            "5/20 loss 1.97\n",
            "5/20 loss 2.01\n",
            "5/20 loss 2.05\n",
            "5/20 loss 2.09\n",
            "5/20 loss 2.12\n",
            "5/20 loss 2.16\n",
            "5/20 loss 2.20\n",
            "5/20 loss 2.25\n",
            "5/20 loss 2.29\n",
            "5/20 loss 2.33\n",
            "5/20 loss 2.38\n",
            "5/20 loss 2.42\n",
            "5/20 loss 2.46\n",
            "5/20 loss 2.50\n",
            "5/20 loss 2.54\n",
            "5/20 loss 2.58\n",
            "5/20 loss 2.62\n",
            "5/20 loss 2.65\n",
            "5/20 loss 2.69\n",
            "5/20 loss 2.73\n",
            "5/20 loss 2.77\n",
            "5/20 loss 2.80\n",
            "5/20 loss 2.84\n",
            "5/20 loss 2.87\n",
            "5/20 loss 2.92\n",
            "5/20 loss 2.96\n",
            "5/20 loss 3.00\n",
            "5/20 loss 3.04\n",
            "5/20 loss 3.07\n",
            "5/20 loss 3.11\n",
            "5/20 loss 3.15\n",
            "5/20 loss 3.19\n",
            "5/20 loss 3.23\n",
            "5/20 loss 3.26\n",
            "5/20 loss 3.30\n",
            "5/20 loss 3.35\n",
            "5/20 loss 3.39\n",
            "5/20 loss 3.43\n",
            "5/20 loss 3.46\n",
            "5/20 loss 3.49\n",
            "5/20 loss 3.52\n",
            "5/20 loss 3.56\n",
            "5/20 loss 3.60\n",
            "5/20 loss 3.65\n",
            "5/20 loss 3.69\n",
            "5/20 loss 3.73\n",
            "5/20 loss 3.77\n",
            "5/20 loss 3.81\n",
            "5/20 loss 3.85\n",
            "5/20 loss 3.89\n",
            "5/20 loss 3.92\n",
            "5/20 loss 3.96\n",
            "5/20 loss 3.99\n",
            "5/20 loss 4.03\n",
            "5/20 loss 4.07\n",
            "5/20 loss 4.11\n",
            "5/20 loss 4.14\n",
            "5/20 loss 4.18\n",
            "5/20 loss 4.22\n",
            "5/20 loss 4.26\n",
            "5/20 loss 4.30\n",
            "5/20 loss 4.34\n",
            "10/20 loss 0.04\n",
            "10/20 loss 0.08\n",
            "10/20 loss 0.12\n",
            "10/20 loss 0.15\n",
            "10/20 loss 0.19\n",
            "10/20 loss 0.21\n",
            "10/20 loss 0.25\n",
            "10/20 loss 0.28\n",
            "10/20 loss 0.31\n",
            "10/20 loss 0.34\n",
            "10/20 loss 0.37\n",
            "10/20 loss 0.41\n",
            "10/20 loss 0.45\n",
            "10/20 loss 0.50\n",
            "10/20 loss 0.54\n",
            "10/20 loss 0.58\n",
            "10/20 loss 0.62\n",
            "10/20 loss 0.66\n",
            "10/20 loss 0.70\n",
            "10/20 loss 0.74\n",
            "10/20 loss 0.77\n",
            "10/20 loss 0.80\n",
            "10/20 loss 0.83\n",
            "10/20 loss 0.87\n",
            "10/20 loss 0.91\n",
            "10/20 loss 0.95\n",
            "10/20 loss 0.98\n",
            "10/20 loss 1.03\n",
            "10/20 loss 1.07\n",
            "10/20 loss 1.11\n",
            "10/20 loss 1.15\n",
            "10/20 loss 1.18\n",
            "10/20 loss 1.22\n",
            "10/20 loss 1.26\n",
            "10/20 loss 1.31\n",
            "10/20 loss 1.34\n",
            "10/20 loss 1.37\n",
            "10/20 loss 1.41\n",
            "10/20 loss 1.45\n",
            "10/20 loss 1.49\n",
            "10/20 loss 1.52\n",
            "10/20 loss 1.56\n",
            "10/20 loss 1.59\n",
            "10/20 loss 1.63\n",
            "10/20 loss 1.67\n",
            "10/20 loss 1.71\n",
            "10/20 loss 1.75\n",
            "10/20 loss 1.79\n",
            "10/20 loss 1.83\n",
            "10/20 loss 1.86\n",
            "10/20 loss 1.89\n",
            "10/20 loss 1.93\n",
            "10/20 loss 1.96\n",
            "10/20 loss 1.99\n",
            "10/20 loss 2.03\n",
            "10/20 loss 2.07\n",
            "10/20 loss 2.11\n",
            "10/20 loss 2.15\n",
            "10/20 loss 2.19\n",
            "10/20 loss 2.23\n",
            "10/20 loss 2.27\n",
            "10/20 loss 2.31\n",
            "10/20 loss 2.35\n",
            "10/20 loss 2.38\n",
            "10/20 loss 2.42\n",
            "10/20 loss 2.46\n",
            "10/20 loss 2.48\n",
            "10/20 loss 2.52\n",
            "10/20 loss 2.55\n",
            "10/20 loss 2.59\n",
            "10/20 loss 2.61\n",
            "10/20 loss 2.64\n",
            "10/20 loss 2.67\n",
            "10/20 loss 2.72\n",
            "10/20 loss 2.76\n",
            "10/20 loss 2.80\n",
            "10/20 loss 2.84\n",
            "10/20 loss 2.86\n",
            "10/20 loss 2.90\n",
            "10/20 loss 2.94\n",
            "10/20 loss 2.97\n",
            "10/20 loss 3.01\n",
            "10/20 loss 3.04\n",
            "10/20 loss 3.08\n",
            "10/20 loss 3.12\n",
            "10/20 loss 3.16\n",
            "10/20 loss 3.20\n",
            "10/20 loss 3.23\n",
            "10/20 loss 3.26\n",
            "10/20 loss 3.28\n",
            "10/20 loss 3.33\n",
            "10/20 loss 3.36\n",
            "10/20 loss 3.40\n",
            "10/20 loss 3.45\n",
            "10/20 loss 3.48\n",
            "10/20 loss 3.52\n",
            "10/20 loss 3.56\n",
            "10/20 loss 3.59\n",
            "10/20 loss 3.63\n",
            "10/20 loss 3.66\n",
            "10/20 loss 3.68\n",
            "10/20 loss 3.72\n",
            "10/20 loss 3.76\n",
            "10/20 loss 3.79\n",
            "10/20 loss 3.83\n",
            "10/20 loss 3.85\n",
            "10/20 loss 3.89\n",
            "10/20 loss 3.92\n",
            "10/20 loss 3.96\n",
            "10/20 loss 3.98\n",
            "10/20 loss 4.02\n",
            "15/20 loss 0.03\n",
            "15/20 loss 0.07\n",
            "15/20 loss 0.11\n",
            "15/20 loss 0.14\n",
            "15/20 loss 0.18\n",
            "15/20 loss 0.19\n",
            "15/20 loss 0.23\n",
            "15/20 loss 0.26\n",
            "15/20 loss 0.29\n",
            "15/20 loss 0.32\n",
            "15/20 loss 0.34\n",
            "15/20 loss 0.38\n",
            "15/20 loss 0.42\n",
            "15/20 loss 0.46\n",
            "15/20 loss 0.50\n",
            "15/20 loss 0.54\n",
            "15/20 loss 0.58\n",
            "15/20 loss 0.62\n",
            "15/20 loss 0.66\n",
            "15/20 loss 0.70\n",
            "15/20 loss 0.73\n",
            "15/20 loss 0.75\n",
            "15/20 loss 0.78\n",
            "15/20 loss 0.82\n",
            "15/20 loss 0.85\n",
            "15/20 loss 0.89\n",
            "15/20 loss 0.93\n",
            "15/20 loss 0.97\n",
            "15/20 loss 1.01\n",
            "15/20 loss 1.04\n",
            "15/20 loss 1.08\n",
            "15/20 loss 1.12\n",
            "15/20 loss 1.15\n",
            "15/20 loss 1.19\n",
            "15/20 loss 1.23\n",
            "15/20 loss 1.26\n",
            "15/20 loss 1.29\n",
            "15/20 loss 1.33\n",
            "15/20 loss 1.37\n",
            "15/20 loss 1.40\n",
            "15/20 loss 1.44\n",
            "15/20 loss 1.47\n",
            "15/20 loss 1.50\n",
            "15/20 loss 1.54\n",
            "15/20 loss 1.58\n",
            "15/20 loss 1.62\n",
            "15/20 loss 1.66\n",
            "15/20 loss 1.69\n",
            "15/20 loss 1.73\n",
            "15/20 loss 1.75\n",
            "15/20 loss 1.78\n",
            "15/20 loss 1.82\n",
            "15/20 loss 1.85\n",
            "15/20 loss 1.87\n",
            "15/20 loss 1.91\n",
            "15/20 loss 1.94\n",
            "15/20 loss 1.98\n",
            "15/20 loss 2.02\n",
            "15/20 loss 2.06\n",
            "15/20 loss 2.10\n",
            "15/20 loss 2.13\n",
            "15/20 loss 2.17\n",
            "15/20 loss 2.21\n",
            "15/20 loss 2.24\n",
            "15/20 loss 2.27\n",
            "15/20 loss 2.31\n",
            "15/20 loss 2.33\n",
            "15/20 loss 2.36\n",
            "15/20 loss 2.40\n",
            "15/20 loss 2.43\n",
            "15/20 loss 2.45\n",
            "15/20 loss 2.47\n",
            "15/20 loss 2.50\n",
            "15/20 loss 2.54\n",
            "15/20 loss 2.58\n",
            "15/20 loss 2.62\n",
            "15/20 loss 2.65\n",
            "15/20 loss 2.68\n",
            "15/20 loss 2.72\n",
            "15/20 loss 2.75\n",
            "15/20 loss 2.78\n",
            "15/20 loss 2.82\n",
            "15/20 loss 2.84\n",
            "15/20 loss 2.88\n",
            "15/20 loss 2.92\n",
            "15/20 loss 2.96\n",
            "15/20 loss 2.99\n",
            "15/20 loss 3.02\n",
            "15/20 loss 3.05\n",
            "15/20 loss 3.07\n",
            "15/20 loss 3.11\n",
            "15/20 loss 3.15\n",
            "15/20 loss 3.18\n",
            "15/20 loss 3.22\n",
            "15/20 loss 3.25\n",
            "15/20 loss 3.29\n",
            "15/20 loss 3.32\n",
            "15/20 loss 3.36\n",
            "15/20 loss 3.39\n",
            "15/20 loss 3.42\n",
            "15/20 loss 3.44\n",
            "15/20 loss 3.47\n",
            "15/20 loss 3.51\n",
            "15/20 loss 3.54\n",
            "15/20 loss 3.58\n",
            "15/20 loss 3.59\n",
            "15/20 loss 3.62\n",
            "15/20 loss 3.65\n",
            "15/20 loss 3.68\n",
            "15/20 loss 3.70\n",
            "15/20 loss 3.74\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (embeddings): Embedding(97, 10)\n",
              "  (linear1): Linear(in_features=10, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=97, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "Qgjydm-BaSCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = CBOW(vocab_size,EMBEDDING_DIM)\n",
        "\n",
        "def test_cbow(model , vocab , word_to_ix) :\n",
        "    word_1 = vocab[10]\n",
        "    word_2 = vocab[5]\n",
        "    \n",
        "    word_1_vec = model.get_word_vector(word_1,word_to_ix)\n",
        "    word_2_vec = model.get_word_vector(word_2,word_to_ix)\n",
        "    \n",
        "    cosine_similarity = (torch.mm(word_1_vec, word_2_vec.transpose(0,1))) / (torch.norm(word_1_vec) * torch.norm(word_2_vec))\n",
        "    similarity = cosine_similarity.data.numpy()[0][0]\n",
        "    print('word1 : ',word_1)\n",
        "    print('word2 : ',word_2)\n",
        "    print('similarity : ',similarity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGhiAUSJaSCp",
        "colab_type": "code",
        "outputId": "41652cfc-d1de-448a-c3b8-d8fb08e9b0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "test_cbow(model,vocab,word_to_ix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word1 :  by\n",
            "word2 :  gazed\n",
            "similarity :  0.31032938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hBinXaEreki_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXPXKHRlBvSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Zi2ykXtFazt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UplQHyBkDHFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5 CNN(Convolution Neural Network)"
      ]
    },
    {
      "metadata": {
        "id": "rLHbm_FxDLds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}