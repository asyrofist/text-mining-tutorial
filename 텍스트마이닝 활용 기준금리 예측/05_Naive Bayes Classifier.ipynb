{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Traning set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set, test set 만들기\n",
    "import pandas as pd\n",
    "\n",
    "data_set = pd.read_csv('./data/model/training_set.csv')\n",
    "training_set = data_set[:int(len(data_set)*0.9)]\n",
    "test_set = data_set[int(len(data_set)*0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 229561\n",
      "10000 / 229561\n",
      "20000 / 229561\n",
      "30000 / 229561\n",
      "40000 / 229561\n",
      "50000 / 229561\n",
      "60000 / 229561\n",
      "70000 / 229561\n",
      "80000 / 229561\n",
      "90000 / 229561\n",
      "100000 / 229561\n",
      "110000 / 229561\n",
      "120000 / 229561\n",
      "130000 / 229561\n",
      "140000 / 229561\n",
      "150000 / 229561\n",
      "160000 / 229561\n",
      "170000 / 229561\n",
      "180000 / 229561\n",
      "190000 / 229561\n",
      "200000 / 229561\n",
      "210000 / 229561\n",
      "220000 / 229561\n"
     ]
    }
   ],
   "source": [
    "# traning : traning set 으로 토큰별 빈도수 계산\n",
    "from collections import defaultdict\n",
    "\n",
    "# 토큰별로 문서내 빈도수 카운팅\n",
    "wordfreq = defaultdict(lambda : [0, 0])\n",
    "for i, row in training_set.iterrows():\n",
    "    words = row['ngrams in doc'].split(',')\n",
    "    for word in words :\n",
    "        if row['lable'] == 1 :\n",
    "            wordfreq[word][1] += 1\n",
    "        elif row['lable'] == -1 :\n",
    "            wordfreq[word][0] += 1\n",
    "    \n",
    "    if i % 10000 == 0 :\n",
    "        print(\"{} / {}\".format(i, training_set.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram list 파일 저장\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(wordfreq, orient='index').to_csv('./data/model/ngram_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary 파일 저장\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "k = 0.5\n",
    "\n",
    "df = pd.read_csv('./data/model/ngram_list.csv', index_col='Unnamed: 0')\n",
    "df[\"freq\"] = df['0']+df['1'] # 전체 토큰별 빈도수 계산\n",
    "df = df.loc[df.freq > 15] # 빈도가 15 초과인것만 필터링\n",
    "df[\"w|pos\"] = (df['1']+k)/(df['1'].sum()+k*2)\n",
    "df[\"w|neg\"] = (df['0']+k)/(df['0'].sum()+k*2)\n",
    "df[\"log(w|pos)\"] = np.log(df[\"w|pos\"])\n",
    "df[\"log(w|neg)\"] = np.log(df[\"w|neg\"])\n",
    "df[\"polarity score\"] = df[\"w|pos\"]/df[\"w|neg\"]\n",
    "df[\"intensity\"] = [x if x > 1 else 1/x for x in df['polarity score']]\n",
    "df[\"lable\"] = [1 if x > 1 else -1 for x in df['polarity score']]\n",
    "df.loc[df.intensity>1.3].to_csv('./data/model/bok_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/model/bok_dictionary.csv', index_col='Unnamed: 0')\n",
    "dic = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) prediction & 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "prob_pos_tot = math.log(df['1'].sum()/(df['1'].sum()+df['0'].sum()))\n",
    "prob_neg_tot = math.log(df['0'].sum()/(df['1'].sum()+df['0'].sum()))\n",
    "\n",
    "TP = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "predict=[]\n",
    "\n",
    "for i, row in test_set[(test_set.lable==1.0) | (test_set.lable==-1.0)].iterrows():\n",
    "    ngrams = row['ngrams in doc'].split(',')\n",
    "    lable = row['lable']\n",
    "    prob_predict = 0\n",
    "    prob_pos = 0\n",
    "    prob_neg = 0\n",
    "    \n",
    "    for token in ngrams :\n",
    "        if token in dic.keys() :\n",
    "            prob_pos += dic[token]['log(w|pos)']\n",
    "            prob_neg += dic[token]['log(w|neg)']\n",
    "    prob_pos = math.exp(prob_pos + prob_pos_tot)\n",
    "    prob_neg = math.exp(prob_neg + prob_neg_tot)\n",
    "    \n",
    "    if prob_pos+prob_neg == 0 :\n",
    "        prob_predict = 0\n",
    "    else :\n",
    "        prob_predict = prob_pos/(prob_pos+prob_neg)\n",
    "        \n",
    "    if prob_predict > 0.5 and lable == 1.0 :\n",
    "        predict.append(1.0)\n",
    "        TP += 1\n",
    "    elif prob_predict > 0.5 and lable == -1.0 :\n",
    "        predict.append(1.0)\n",
    "        FP += 1\n",
    "    elif prob_predict < 0.5 and lable == 1.0 :\n",
    "        predict.append(-1.0)\n",
    "        FN += 1\n",
    "    elif prob_predict < 0.5 and lable == -1.0 :\n",
    "        predict.append(-1.0)\n",
    "        TN += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_hat):\n",
    "    ssr = 0\n",
    "    sst = 0\n",
    "    e = np.subtract(y_true, y_hat)\n",
    "    y_mean = np.mean(y_true)\n",
    "    for item in e:\n",
    "        ssr += item**2\n",
    "    for item in y_true:\n",
    "        sst += (item - y_mean)**2\n",
    "    r2 = 1 - ssr / sst\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8554504743825104"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared(lable_ls, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC = 0.5518053375196232\n",
      "ERR = 0.44819466248037676\n",
      "SN = 0.7241640617599697\n",
      "PREC = 0.6006914433880726\n"
     ]
    }
   ],
   "source": [
    "#ACC = (TP + TN)  / (전체 데이타 수 = P + N)\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"ACC = {}\".format(ACC))\n",
    "# ERR = (FN+FP) / (전체 데이타수 = P+N)\n",
    "ERR = (FN+FP) / (TP + TN + FP + FN)\n",
    "print(\"ERR = {}\".format(ERR))\n",
    "# SN = (TP) / P\n",
    "SN = (TP) / (TP + FN)\n",
    "print(\"SN = {}\".format(SN))\n",
    "# PREC = TP / (TP+FP)\n",
    "PREC = TP / (TP+FP)\n",
    "print(\"PREC = {}\".format(PREC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
